{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<script>\n",
    "  function code_toggle() {\n",
    "    if (code_shown){\n",
    "      $('div.input').hide('500');\n",
    "      $('#toggleButton').val('Show Code')\n",
    "    } else {\n",
    "      $('div.input').show('500');\n",
    "      $('#toggleButton').val('Hide Code')\n",
    "      \n",
    "    }\n",
    "    code_shown = !code_shown\n",
    "  }\n",
    "\n",
    "  $( document ).ready(function(){\n",
    "    code_shown=false;\n",
    "    $('div.input').hide()\n",
    "  });\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" id=\"toggleButton\" value=\"Show Code\"></form>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Analysis Data PFT Scanner Pilots -- Extracting reports from online questionnaires"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and relevant variables participants\n",
    " --------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_exp1 = pd.read_csv('/Users/pradyumna/OneDrive - University College London/PhD Projects/PFT_MRI_Experiment/Scanner Pilot/All_Behavioral/PFT_Choice_Onsets_Partic_AllJoined.csv') \n",
    "data_exp_ratings_2 = pd.read_csv('/Users/pradyumna/OneDrive - University College London/PhD Projects/PFT_MRI_Experiment/Scanner Pilot/All_Behavioral/PFT_Rate_Onsets_Partic_AllJoined.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert to exclude particitipants\n",
    "excludedPart = []\n",
    "for i in excludedPart:\n",
    "    data_exp1 = data_exp1[(data_exp1.Part != i)]\n",
    "    data_exp_ratings_2 = data_exp_ratings_2[(data_exp_ratings_2.Part != i)]\n",
    "print (data_exp1[\"part\"].unique())\n",
    "print ('Number of participants: ' + str(len(data_exp1[\"part\"].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_exp1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_exp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_exp_ratings_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_exp1=data_exp1.rename(index=str, columns={\"choiceTime\":\"RT\",\n",
    "                                              \"part\":\"Part\"})\n",
    "\n",
    "data_exp_ratings_2 = data_exp_ratings_2.rename(index=str, columns={\"choiceTime\":\"RT\",\n",
    "                                              \"part\":\"Part\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## drop NaNs from choice rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_exp1 = data_exp1.dropna(axis = 0, how ='any') \n",
    "#data_exp_ratings_2 = data_exp_ratings_2.dropna(axis = 0, how ='any') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_exp1 = data_exp1.reset_index()\n",
    "data_exp_ratings_2 = data_exp_ratings_2.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add extra value information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_exp1[\"TotVal1\"] = data_exp1['RRat1']+ data_exp1['LRat1']\n",
    "data_exp1[\"TotVal2\"] = data_exp1['RRat2']+ data_exp1['LRat2']\n",
    "\n",
    "\n",
    "data_exp1[\"DVal1\"] = data_exp1['RRat1'] - data_exp1['LRat1']\n",
    "data_exp1[\"absDVal1\"] = np.abs(data_exp1[\"DVal1\"] )\n",
    "\n",
    "data_exp1[\"DVar1\"] = data_exp1['RVar1'] - data_exp1['LVar1']\n",
    "data_exp1[\"absDVar1\"] = np.abs(data_exp1[\"DVar1\"] )\n",
    "\n",
    "data_exp1[\"DVal2\"] = data_exp1['RRat2'] - data_exp1['LRat2']\n",
    "data_exp1[\"absDVal2\"] = np.abs(data_exp1[\"DVal2\"] )\n",
    "\n",
    "data_exp1[\"DVar2\"] = data_exp1['RVar2'] - data_exp1['LVar2']\n",
    "data_exp1[\"absDVar2\"] = np.abs(data_exp1[\"DVar2\"] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add z-scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_exp1[\"zDVal1\"] = z_score1(data_exp1,'Part',\"DVal1\")\n",
    "data_exp1[\"zabsDVal1\"] = z_score1(data_exp1,'Part',\"absDVal1\")\n",
    "\n",
    "data_exp1[\"zDVal2\"] = z_score1(data_exp1,'Part',\"DVal2\")\n",
    "data_exp1[\"zabsDVal2\"] = z_score1(data_exp1,'Part',\"absDVal2\")\n",
    "\n",
    "data_exp1[\"zDVar1\"] = z_score1(data_exp1,'Part',\"DVar1\")\n",
    "data_exp1[\"zabsDVar1\"] = z_score1(data_exp1,'Part',\"absDVar1\")\n",
    "\n",
    "data_exp1[\"zDVar2\"] = z_score1(data_exp1,'Part',\"DVar2\")\n",
    "data_exp1[\"zabsDVar2\"] = z_score1(data_exp1,'Part',\"absDVar2\")\n",
    "\n",
    "data_exp1[\"zTotVal1\"] = z_score1(data_exp1,'Part',\"TotVal1\")\n",
    "data_exp1[\"zTotVal2\"] = z_score1(data_exp1,'Part',\"TotVal2\")\n",
    "data_exp1[\"zRT\"] = z_score1(data_exp1,'Part',\"RT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## correct option according to rating given in frame 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Correct = []\n",
    "for i in range(len(data_exp1)):\n",
    "    if data_exp1.frame[i] == 1:\n",
    "        if (data_exp1.choice[i] == 1 and (data_exp1.LValOn[i] <= data_exp1.RValOn[i])) or (data_exp1.choice[i] == -1 and (data_exp1.LValOn[i] >= data_exp1.RValOn[i])):\n",
    "            Correct.append(1)\n",
    "        else:\n",
    "            Correct.append(0)\n",
    "    if data_exp1.frame[i] == 2:\n",
    "        if (data_exp1.choice[i] == 1 and (data_exp1.LValOn[i] >= data_exp1.RValOn[i])) or (data_exp1.choice[i] == -1 and (data_exp1.LValOn[i] <= data_exp1.RValOn[i])):\n",
    "            Correct.append(1)\n",
    "        else:\n",
    "            Correct.append(0)\n",
    "\n",
    "data_exp1[\"correctOn\"] = Correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## change choices from -1 to 0 for left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choices = []\n",
    "for i in range(len(data_exp1)):\n",
    "        if (data_exp1.choice[i] == 1):\n",
    "            choices.append(1)\n",
    "        else:\n",
    "            choices.append(0)\n",
    "\n",
    "data_exp1[\"choices\"] = choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_exp1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rating data analysis for both frames\n",
    "------------------------\n",
    "## frame 1: like / frame 2: dislike\n",
    "## pet number id: 1:dog ; 2:cat ; 5:parrot ; 6: hamster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1. mean rating in both frames \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.set(font_scale=1.5, style='white')\n",
    "#ax = data_exp_ratings_2.loc[(data_exp_ratings_2['Part'] == 1)].plot.bar(x='nameId',y=['rat1','rat2'], figsize=(20,5), )\n",
    "#plt.suptitle('Participant ' + str(1), fontsize = 25)#\n",
    "\n",
    "#sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_exp_ratings_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.reaction times for each participant in frame 1 (blue) and 2 (red)\n",
    "### substract time till the response is available (raw RT in this case is the time from the beginning of the trial, which includes the sound stimuli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "figure(figsize=(16,7))\n",
    "\n",
    "sns.set(font_scale=1.5, style='white')\n",
    "\n",
    "width = 0.25\n",
    "#partNames = data_exp1.Part.unique()\n",
    "partNames = range(3, 3+len(data_exp1[\"Part\"].unique()))\n",
    "\n",
    "\n",
    "\n",
    "for i in np.arange(len(partNames)):\n",
    "    RT1 = data_exp1.loc[(data_exp1['Part'] == partNames[i]) & (data_exp1['frame'] == 1) ].RT-3.5\n",
    "    RT2 = data_exp1.loc[(data_exp1['Part'] == partNames[i]) & (data_exp1['frame'] == 2) ].RT-3.5\n",
    "\n",
    "    RT_mean1 = data_exp1.loc[(data_exp1['Part'] == partNames[i]) & (data_exp1['frame'] == 1) ].RT.mean()-3.5\n",
    "    RT_mean2 = data_exp1.loc[(data_exp1['Part'] == partNames[i]) & (data_exp1['frame'] == 2) ].RT.mean()-3.5\n",
    "    print ('participant: ' + str(i))\n",
    "    print ('RT frame 1: ' + str(RT_mean1))\n",
    "    print ('RT frame 2: ' + str(RT_mean2))\n",
    "\n",
    "    plt.bar(i-0.25, RT_mean1,width,color='b', label = 'Like')\n",
    "\n",
    "    plt.scatter([i-0.25]*len(RT1),RT1 ,color='black', alpha=0.3, marker='o', label = 'Like')\n",
    "\n",
    "\n",
    "    plt.bar(i+0.25, RT_mean2,width,color='r', label = 'Dislike')\n",
    "    plt.scatter([i+0.25]*len(RT2),RT2 ,color='black', alpha=0.3, marker='o', label = 'Dislike')\n",
    "\n",
    "plt.xticks(range(len(partNames)), partNames)\n",
    "plt.xlabel(\"Subject\")\n",
    "plt.ylabel(\"RT [s] \")\n",
    "#plt.xticks([i-0.5,i+0.5],[\"Like \",\"Dislike\"], rotation=0, fontsize=25)\n",
    "#plt.legend()\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. participant densities rate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_densities(data_exp1,'RRat1', title = 'Rate Frame 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_densities(data_exp1,'RRat2', title = 'Rate Frame 2 ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. participants densities variability \n",
    "## (variability corresponds to the standard deviation of the ratings for each pet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_densities(data_exp1,'RVar1', title = 'Variability Frame 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_densities(data_exp1,'RVar2', title = 'Variability Frame 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.Pet ratings (value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Value Online vs Exemplar value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corrPlotSimple(data_exp_ratings_2, 'rat1','Ratings Frame 1','rat2','Ratings Frame 2')\n",
    "for part in data_exp1[\"Part\"].unique(): \n",
    "\n",
    "    corrPlotSimple(data_exp_ratings_2.loc[(data_exp_ratings_2['Part'] == part)], 'ValOnl','Value Online','ExVal','Exemplar Value', title = 'S0'+str(part))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Value Rating Like (in task) vs Value Online"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corrPlotSimple(data_exp_ratings_2, 'rat1','Ratings Frame 1','rat2','Ratings Frame 2')\n",
    "for part in data_exp1[\"Part\"].unique(): \n",
    "\n",
    "    corrPlotSimple(data_exp_ratings_2.loc[(data_exp_ratings_2['Part'] == part)], 'ValOnl','Value Online','Val1','Value Task, Like Frame', title = 'S0'+str(part))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Value Rating Dislike (in task) vs Value Online"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corrPlotSimple(data_exp_ratings_2, 'rat1','Ratings Frame 1','rat2','Ratings Frame 2')\n",
    "for part in data_exp1[\"Part\"].unique(): \n",
    "\n",
    "    corrPlotSimple(data_exp_ratings_2.loc[(data_exp_ratings_2['Part'] == part)], 'ValOnl','Value Online','Val2','Value Task, Dislike Frame', title = 'S0'+str(part))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## use only rating trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_exp_onlyRat = data_exp_ratings_2.loc[data_exp_ratings_2['rating']>0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_exp_onlyRatL = data_exp_onlyRat.loc[data_exp_onlyRat['frame'] == 1].copy()\n",
    "data_exp_onlyRatD = data_exp_onlyRat.loc[data_exp_onlyRat['frame'] == 2].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corrPlotSimple(data_exp_ratings_2, 'rat1','Ratings Frame 1','rat2','Ratings Frame 2')\n",
    "for part in data_exp1[\"Part\"].unique(): \n",
    "\n",
    "    corrPlotSimple(data_exp_onlyRatL.loc[(data_exp_onlyRatL['Part'] == part)], 'ValOnl','Value Online','rating','Task Ratings Like ', title = 'S0'+str(part))\n",
    "    corrPlotSimple(data_exp_onlyRatD.loc[(data_exp_onlyRatD['Part'] == part)], 'ValOnl','Value Online','rating','Task Ratings Dislike ', title = 'S0'+str(part))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Choice data analysis\n",
    "-----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_densities(data_exp1,'choices', title = 'Choice (0: left ; 1: right)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_densities(data_exp1,'RT',title = 'RT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_densities(data_exp1,'frame',title = 'Frame')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This plot is just to check if I am presenting a comparable number of trials for each frames (in some cases is different because participants can miss the response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. accuracy per participant - Based on online rankngs of Pets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = pd.DataFrame( columns = [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_like = []\n",
    "accuracy_dislike = []\n",
    "\n",
    "for i in data_exp1.Part.unique():\n",
    "    print(i)\n",
    "    accuracy_like.append(data_exp1.loc[(data_exp1['frame'] == 1) & (data_exp1['Part'] == i)].correctOn.mean())\n",
    "    #print(accuracy_like)\n",
    "\n",
    "    accuracy_dislike.append(data_exp1.loc[(data_exp1['frame'] == 2) & (data_exp1['Part'] == i)].correctOn.mean())\n",
    "    #print(accuracy_dislike)\n",
    "\n",
    "accuracies['participant'] = range(len(data_exp1.Part.unique()))\n",
    "accuracies['like'] = accuracy_like\n",
    "accuracies['dislike'] = accuracy_dislike\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies.plot.bar(x='participant',y=['like','dislike'], figsize=(20,5),title = 'Accuracy according to rating frame 1',color = ['b','r'])\n",
    "ax.set_ylim(0, 1)\n",
    "plt.xticks(range(0,len(data_exp1[\"Part\"].unique())), data_exp1[\"Part\"].unique())\n",
    "\n",
    "sns.despine()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split dataframe for like and dislike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_expL = data_exp1.loc[(data_exp1['frame'] == 1)] # 1 = Like, 2 = Dislike\n",
    "data_expD = data_exp1.loc[(data_exp1['frame'] == 2)] # 1 = Like, 2 = Dislike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_expL = data_exp1.loc[(data_exp1['frame'] == 1) & (data_exp1['Part'] == 4)] # 1 = Like, 2 = Dislike\n",
    "#data_expD = data_exp1.loc[(data_exp1['frame'] == 2) & (data_exp1['Part'] == 4)] # 1 = Like, 2 = Dislike"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. relationship between RT and |DV| (using ratings given in LIKE frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. logistic plots for choice in like and dislike frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticplot_all_part( data=data_expL, xaxis='zDValOn', yaxis='choices', ylab='P(Right Item)', xlab= r'ΔVal $_{frame1}$',\n",
    "                 modlowcol='#4F6A9A', title='Like frame', parvar='Part')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticplot_all_part( data=data_expD, xaxis='zDValOn', yaxis='choices', ylab='P(Right Item)', xlab= r'ΔVal $_{frame1}$',\n",
    "                 modlowcol='#AC5255', title='Dislike frame', parvar='Part')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. considering logistics plots aggregating all participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticplot_all( data=data_expL, xaxis='zDValOn', yaxis='choices', ylab='P(Right Item)', xlab= r'ΔVal $_{frame1}$',\n",
    "                 modlowcol='#4F6A9A', title='Like frame', parvar='Part')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticplot_all( data=data_expD, xaxis='zDValOn', yaxis='choices', ylab='P(Right Item)', xlab= r'ΔVal $_{frame1}$',\n",
    "                 modlowcol='#AC5255', title='Dislike frame', parvar='Part')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. (preliminar) regression analysis on Choice\n",
    "### zDVal1: difference in value (mean ratings for pet right -left) in like frame (frame 1)\n",
    "### zDVal2: difference in value (mean ratings for pet right -left) in dislike frame (frame 2)\n",
    "### zDVarX: difference in rating variability (mean variability pet right -left)  in frame X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%R -i data_exp1\n",
    "data_exp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "# Separating the data for both conditions \n",
    "data_exp1_Like <- data_exp1[ which(data_exp1$frame=='1'), ]\n",
    "data_exp1_DisLike <- data_exp1[ which(data_exp1$frame=='2'), ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "title_plot = \"Choice \"\n",
    "\n",
    "ModelChoiceL_1 <- glm(choices ~ zDValOn , data=data_exp1_Like, family=binomial(link=\"logit\"))\n",
    "ModelChoiceD_1 <- glm(choices ~ zDValOn , data=data_exp1_DisLike, family=binomial(link=\"logit\"))\n",
    "\n",
    "BIC1 = BIC(ModelChoiceL_1)\n",
    "BIC2 = BIC(ModelChoiceD_1)\n",
    "print(\"Like BIC:\")\n",
    "print(BIC1)\n",
    "print(\"DisLike BIC:\")\n",
    "print(BIC2)\n",
    "\n",
    "coefplot(ModelChoiceD_1,intercept=FALSE,vertical = FALSE,  col.pts=\"red\", cex.var=1.5, cex.pts=2, mar = c(8,4,5,1) ,ylim=c(-10, 10) ,main=title_plot)\n",
    "coefplot(ModelChoiceL_1, intercept=FALSE, vertical = FALSE, add=TRUE, col.pts=\"blue\", cex.var=1.5, cex.pts=2,mar = c(8,4,5,1))\n",
    "legend(\"topright\",  legend=c(\"Dislike\", \"Like\"),col=c(\"red\", \"blue\"), lty=1:1, cex=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Since I don't have confidence I try to predict RT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "title_plot = \"RT \"\n",
    "\n",
    "ModelChoiceL_1 <- glm(zRT ~ zAbsDValOn   , data=data_exp1_Like, )\n",
    "ModelChoiceD_1 <- glm(zRT ~ zAbsDValOn   , data=data_exp1_DisLike, )\n",
    "\n",
    "BIC1 = BIC(ModelChoiceL_1)\n",
    "BIC2 = BIC(ModelChoiceD_1)\n",
    "print(\"Like BIC:\")\n",
    "print(BIC1)\n",
    "print(\"DisLike BIC:\")\n",
    "print(BIC2)\n",
    "\n",
    "coefplot(ModelChoiceD_1,intercept=FALSE,vertical = FALSE,  col.pts=\"red\", cex.var=1.5, cex.pts=2, mar = c(8,4,5,1) ,ylim=c(-1, 1) ,main=title_plot)\n",
    "coefplot(ModelChoiceL_1, intercept=FALSE, vertical = FALSE, add=TRUE, col.pts=\"blue\", cex.var=1.5, cex.pts=2,mar = c(8,4,5,1))\n",
    "legend(\"topright\",  legend=c(\"Dislike\", \"Like\"),col=c(\"red\", \"blue\"), lty=1:1, cex=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "title_plot = \"RT \"\n",
    "\n",
    "ModelChoiceL_1 <- glm(zRT ~ zabsDVal1 + zTotVal2  , data=data_exp1_Like, )\n",
    "ModelChoiceD_1 <- glm(zRT ~ zabsDVal1 + zTotVal2  , data=data_exp1_DisLike, )\n",
    "\n",
    "BIC1 = BIC(ModelChoiceL_1)\n",
    "BIC2 = BIC(ModelChoiceD_1)\n",
    "print(\"Like BIC:\")\n",
    "print(BIC1)\n",
    "print(\"DisLike BIC:\")\n",
    "print(BIC2)\n",
    "\n",
    "coefplot(ModelChoiceD_1,intercept=FALSE,vertical = FALSE,  col.pts=\"red\", cex.var=1.5, cex.pts=2, mar = c(8,4,5,1) ,ylim=c(-1, 1) ,main=title_plot)\n",
    "coefplot(ModelChoiceL_1, intercept=FALSE, vertical = FALSE, add=TRUE, col.pts=\"blue\", cex.var=1.5, cex.pts=2,mar = c(8,4,5,1))\n",
    "legend(\"topright\",  legend=c(\"Dislike\", \"Like\"),col=c(\"red\", \"blue\"), lty=1:1, cex=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------\n",
    "\n",
    "# Import toolboxes and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.core.frame import DataFrame as DF\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(color_codes=True)\n",
    "#np.random.seed(sum(map(ord, \"distributions\")))\n",
    "from sklearn import linear_model  # packages for the logistic regression function to plot the logistic regression \n",
    "from sklearn.linear_model import LogisticRegression # packages for the logistic regression function to plot the logistic regression \n",
    "import scipy\n",
    "from scipy import stats, integrate\n",
    "from scipy.stats import mode\n",
    "from scipy.stats.stats import pearsonr # Pearson's correlation\n",
    "from copy import copy as copy\n",
    "import operator as operator\n",
    "import pylab\n",
    "\n",
    "# Plotting tools\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.patches as mpatches\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "%pylab inline\n",
    "figsize(5, 5)\n",
    "\n",
    "import glob\n",
    "\n",
    "import os\n",
    "# Added to avoid OMP:error#15\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logisticplot_all (data, xaxis='zDV', yaxis='G_choice', ylab='P(Chose Reference Item)', xlab='DV (Z-score)',\n",
    "                 modlowcol='#AAAAAA', title='empty', parvar='SubNo'):\n",
    "    \n",
    "    sns.set(font_scale=1.5, style='white')\n",
    "    fig = figure(figsize=(8,7))\n",
    "    fig.set_facecolor('white')\n",
    "    \n",
    "    # defining the sigmoid function\n",
    "    def model(x):\n",
    "        y = 1 / (1 + np.exp(-x))\n",
    "        return y\n",
    "    \n",
    "    sub = plt.subplot()\n",
    "\n",
    "    #run the classifier\n",
    "    clf = linear_model.LogisticRegression(C=1e5)\n",
    "\n",
    "    logit_all = {}\n",
    "\n",
    "    # I think this defines the problem space\n",
    "    X_test = np.linspace(-5,10,300)\n",
    "\n",
    "   #fitting the predictive logistic model for all the trials, for a participant specified by x\n",
    "            # first I specify the value difference right - left, then I specify the choices, left or right\n",
    "    clf.fit(data[xaxis][:, np.newaxis],\n",
    "            data[yaxis])\n",
    "    logit_all = model(X_test * clf.coef_ + clf.intercept_).ravel()\n",
    "\n",
    "    #print ('Part: ',x ,' High measure:logit coef =',clf.coef_, '; Intercept: ', clf.intercept_)\n",
    "    \n",
    "    all_coef = clf.coef_\n",
    "    all_intercept = clf.intercept_\n",
    "    \n",
    "    #Plotting the predictive lines\n",
    "    line_all = sub.plot(X_test, logit_all, color=modlowcol, linewidth=3, zorder=5,linestyle='-')\n",
    "\n",
    "   # #Plotting the binned data\n",
    "   # data['DVBin2'] = data.groupby(parvar).apply(parsplit, input=xaxis, quantiles=4).values\n",
    "    \n",
    "   # # determine the x coordinates\n",
    "   # x_cords= data.groupby('DVBin2')[xaxis].mean()\n",
    "    \n",
    "   # # determine low y coordinates\n",
    "   # y_cords_low = data.loc[(data[moderator]==0), :].groupby('DVBin2')[yaxis].mean().values\n",
    "    \n",
    "   # # determine low y standard errors\n",
    "   # test = pd.DataFrame(data.loc[(data[moderator]==0), :].groupby(['DVBin2', parvar])[yaxis].mean()).reset_index()\n",
    "   # y_low_error = test.groupby('DVBin2')[yaxis].std()/np.sqrt(len(test[parvar].unique()))\n",
    "    \n",
    "    \n",
    "   # # determine high y coordinates\n",
    "   # y_cords_high = data.loc[(data[moderator]==1), :].groupby('DVBin2')[yaxis].mean().values\n",
    "    \n",
    "   # # determine high y standard errors\n",
    "   # test2 = pd.DataFrame(data.loc[data[moderator]==1, :].groupby(['DVBin2', parvar])[yaxis].mean()).reset_index()\n",
    "   # y_high_error = test2.groupby('DVBin2')[yaxis].std()/np.sqrt(len(test[parvar].unique()))\n",
    "    \n",
    "   # # plot the low points\n",
    "   # plt.scatter(x_cords, y_cords_low, c=modlowcol, marker='D', s=60, zorder=1)\n",
    "   # # plot low error bars\n",
    "   # plt.errorbar(x_cords, y_cords_low, yerr=y_low_error, fmt='o', zorder=3, c=modlowcol)\n",
    "    \n",
    "   # # plot the high points\n",
    "   # plt.scatter(x_cords, y_cords_high, c=modhighcol, marker='o', s=60, zorder=2)\n",
    "   # # plot high error bars\n",
    "   # plt.errorbar(x_cords, y_cords_high, yerr=y_high_error, fmt='o', zorder=4, c=modhighcol)\n",
    "    \n",
    "    \n",
    "    # Set Labels\n",
    "    sub.set_ylabel(ylab, fontsize=25)\n",
    "    sub.set_xlabel(xlab, fontsize=25)\n",
    "\n",
    "    # Set Ticks\n",
    "    sub.set_xticks((-5,-3,-1,1,3,5))\n",
    "    sub.set_yticks((0,0.25,0.5,0.75,1))\n",
    "    sub.tick_params(axis='both', which='major', labelsize=20)\n",
    "\n",
    "    # Set Limits\n",
    "    sub.set_ylim(-0.01, 1.01)\n",
    "    sub.set_xlim(-5, 5)\n",
    "\n",
    "    # Set Title\n",
    "    if title == 'empty':\n",
    "        sub.set_title('')\n",
    "    else:\n",
    "        sub.set_title(title)\n",
    "    \n",
    "    #sub.legend(loc=0, prop={'size':20})\n",
    "    sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logisticplot_all_part (data, xaxis='zDV', yaxis='G_choice', ylab='P(Chose Reference Item)', xlab='DV (Z-score)',\n",
    "                 modlowcol='#AAAAAA', title='empty', parvar='SubNo'):\n",
    "    \n",
    " \n",
    "    # a list of all the participants in the dataset\n",
    "    participants = data.loc[:, 'Part'].unique()\n",
    "    fig = figure(figsize=(20,10))\n",
    "    fig.set_facecolor('white')\n",
    "    \n",
    "    \n",
    "    # Counter to know where to plot the particpant\n",
    "    order = 1\n",
    "\n",
    "    \n",
    "    for x in participants:\n",
    "\n",
    "            sub={}\n",
    "            sub['%s' % x] = plt.subplot(int(len(participants)/6+1), 6, order)\n",
    "\n",
    "            data_in = data.loc[data['Part'] == x]\n",
    "            sns.set(font_scale=1.5, style='white')\n",
    "            \n",
    "            # defining the sigmoid function\n",
    "            def model(x):\n",
    "                y = 1 / (1 + np.exp(-x))\n",
    "                return y\n",
    "\n",
    "            sub['%s' % x].set_title('participant %s' % x)\n",
    "\n",
    "\n",
    "            #run the classifier\n",
    "            clf = linear_model.LogisticRegression(C=1e5)\n",
    "\n",
    "            logit_all = {}\n",
    "\n",
    "            # I think this defines the problem space\n",
    "            X_test = np.linspace(-5,10,300)\n",
    "\n",
    "           #fitting the predictive logistic model for all the trials, for a participant specified by x\n",
    "                    # first I specify the value difference right - left, then I specify the choices, left or right\n",
    "            clf.fit(data_in[xaxis][:, np.newaxis],\n",
    "                    data_in[yaxis])\n",
    "            logit_all = model(X_test * clf.coef_ + clf.intercept_).ravel()\n",
    "\n",
    "            #print ('Part: ',x ,' High measure:logit coef =',clf.coef_, '; Intercept: ', clf.intercept_)\n",
    "\n",
    "            all_coef = clf.coef_\n",
    "            all_intercept = clf.intercept_\n",
    "\n",
    "            #Plotting the predictive lines\n",
    "            line_all = sub['%s' % x].plot(X_test, logit_all, color=modlowcol, linewidth=3, linestyle='-')\n",
    "            #line_all = sub['%s' % x].plot(X_test, logit_all, color=\"#000000\", linewidth=3, label=modlow, zorder=5,linestyle='--')\n",
    "\n",
    "           # #Plotting the binned data\n",
    "           # data['DVBin2'] = data.groupby(parvar).apply(parsplit, input=xaxis, quantiles=4).values\n",
    "\n",
    "           # # determine the x coordinates\n",
    "           # x_cords= data.groupby('DVBin2')[xaxis].mean()\n",
    "\n",
    "           # # determine low y coordinates\n",
    "           # y_cords_low = data.loc[(data[moderator]==0), :].groupby('DVBin2')[yaxis].mean().values\n",
    "\n",
    "           # # determine low y standard errors\n",
    "           # test = pd.DataFrame(data.loc[(data[moderator]==0), :].groupby(['DVBin2', parvar])[yaxis].mean()).reset_index()\n",
    "           # y_low_error = test.groupby('DVBin2')[yaxis].std()/np.sqrt(len(test[parvar].unique()))\n",
    "\n",
    "    \n",
    "           # # determine high y coordinates\n",
    "           # y_cords_high = data.loc[(data[moderator]==1), :].groupby('DVBin2')[yaxis].mean().values\n",
    "\n",
    "           # # determine high y standard errors\n",
    "           # test2 = pd.DataFrame(data.loc[data[moderator]==1, :].groupby(['DVBin2', parvar])[yaxis].mean()).reset_index()\n",
    "           # y_high_error = test2.groupby('DVBin2')[yaxis].std()/np.sqrt(len(test[parvar].unique()))\n",
    "\n",
    "           # # plot the low points\n",
    "           # plt.scatter(x_cords, y_cords_low, c=modlowcol, marker='D', s=60, zorder=1)\n",
    "           # # plot low error bars\n",
    "           # plt.errorbar(x_cords, y_cords_low, yerr=y_low_error, fmt='o', zorder=3, c=modlowcol)\n",
    "\n",
    "           # # plot the high points\n",
    "           # plt.scatter(x_cords, y_cords_high, c=modhighcol, marker='o', s=60, zorder=2)\n",
    "           # # plot high error bars\n",
    "           # plt.errorbar(x_cords, y_cords_high, yerr=y_high_error, fmt='o', zorder=4, c=modhighcol)\n",
    "\n",
    "    \n",
    "            # Set Labels\n",
    "            #sub['%s' % x].set_ylabel(ylab, fontsize=30)\n",
    "           # sub['%s' % x].set_xlabel(xlab, fontsize=30)\n",
    "\n",
    "            # Set Ticks\n",
    "            sub['%s' % x].set_xticks((-5,-3,-1,1,3,5))\n",
    "            sub['%s' % x].set_yticks((0,0.25,0.5,0.75,1))\n",
    "            sub['%s' % x].tick_params(axis='both', which='major', labelsize=20)\n",
    "\n",
    "            # Set Limits\n",
    "            sub['%s' % x].set_ylim(-0.01, 1.01)\n",
    "            sub['%s' % x].set_xlim(-5, 5)\n",
    "            order += 1\n",
    "\n",
    "\n",
    "    fig.text(0.5, 0.0, xlab, fontsize= 30, ha='center')\n",
    "    fig.text(0.0, 0.5, ylab,fontsize= 30, va='center', rotation='vertical')\n",
    "    \n",
    "    #sub.legend(loc=0, prop={'size':20})\n",
    "    fig.suptitle(title, fontsize = 25)\n",
    "\n",
    "    \n",
    "    sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_score1(data_all, part_def,z_score_var):\n",
    "    z_matrix=[]\n",
    "    z_matrix_aux=[]\n",
    "\n",
    "    for i in (data_all[part_def].unique()):\n",
    "        Choicedata = data_all.loc[data_all[part_def] == i]    \n",
    "    \n",
    "        pX_A= pd.to_numeric(Choicedata[z_score_var]) \n",
    "        pX_zA= (pX_A - np.mean(pX_A))/np.std(pX_A)\n",
    "\n",
    "        z_matrix_aux= pX_zA.values\n",
    "    \n",
    "        for  j in range(len(z_matrix_aux)):    \n",
    "            z_matrix.append(z_matrix_aux[j])\n",
    "    return z_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def participant_densities(data, var, xlim=(0,100), rug=True, title = ''):\n",
    "    # a counter that tells us where a given participant's data should be plotted\n",
    "    order = 1\n",
    "\n",
    "    # a list of all the participants in the dataset\n",
    "    participants = data.loc[:, 'Part'].unique()\n",
    "\n",
    "    # defining the figure size\n",
    "    sns.set_style('white')\n",
    "    fig = figure(figsize=(40,20))\n",
    "\n",
    "    for x in participants:\n",
    "        # defining the sub figures\n",
    "            sub={}\n",
    "            sub['%s' % x] = plt.subplot(len(participants)/2, 4, order)\n",
    "            sns.kdeplot(data.loc[data['Part'] == x, var].values, ax = sub['%s' % x], shade=True)\n",
    "            #if rug==True:\n",
    "            #    sns.rugplot(data.loc[data['Part'] == x, var].values, ax = sub['%s' % x])\n",
    "            sub['%s' % x].set_title('participant %s' % x)\n",
    "            #sub['%s' % x].set_xlim(xlim)\n",
    "            order += 1\n",
    "    fig.suptitle(title, fontsize = 25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrPlotSimple(data_exp1, x_variable,x_varlabel,y_variable,y_varlabel, title=''):\n",
    "    \n",
    "    data_exp1_drop = data_exp1.dropna(subset=[x_variable,y_variable])\n",
    "\n",
    "    results = pearsonr(data_exp1_drop[x_variable], data_exp1_drop[y_variable])\n",
    "    print (\"Pearson's r = {0}\".format(np.round(results[0], 3)), \"p = \", np.round(results[1], 3))\n",
    "    \n",
    "    f = plt.figure(figsize=(8, 8))\n",
    "    sns.set(style='white', font_scale=1.8)\n",
    "    ax = sns.regplot(data=data_exp1_drop, x= x_variable, y=y_variable, fit_reg=False, ci=0, color='#000000', scatter_kws={'s':70})\n",
    "    ax.set(ylabel=y_varlabel, xlabel=x_varlabel)\n",
    "    x=data_exp1_drop[x_variable]\n",
    "    y=data_exp1_drop[y_variable]\n",
    "    fit = np.polyfit(x, y, deg=1)\n",
    "    future = np.arange(min(x)-0.2, max(x)+0.2, 0.01)\n",
    "    fit_fn = np.poly1d(fit)\n",
    "    future_fit = np.polyval(fit_fn, future)\n",
    "    ax.plot(future, future_fit, color='Red', lw=3)\n",
    "    ax.set_title(title, fontsize = 25)\n",
    "\n",
    "    sns.despine()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrPlotPart(data_exp1, x_variable,x_varlabel,y_variable,y_varlabel, title=''):\n",
    "    \n",
    "    data_exp1_drop = data_exp1.dropna(subset=[x_variable,y_variable])\n",
    "\n",
    "    results = pearsonr(data_exp1_drop[x_variable], data_exp1_drop[y_variable])\n",
    "    print (\"Pearson's r = {0}\".format(np.round(results[0], 3)), \"p = \", np.round(results[1], 3))\n",
    "    \n",
    "    #f = plt.figure(figsize=(8, 8))\n",
    "    sns.set(style='white', font_scale=1.8)\n",
    "    ax = sns.regplot(data=data_exp1_drop, x= x_variable, y=y_variable, fit_reg=False, ci=0, color='#000000', scatter_kws={'s':70})\n",
    "    ax.set(ylabel=y_varlabel, xlabel=x_varlabel)\n",
    "    x=data_exp1_drop[x_variable]\n",
    "    y=data_exp1_drop[y_variable]\n",
    "    fit = np.polyfit(x, y, deg=1)\n",
    "    future = np.arange(min(x)-0.2, max(x)+0.2, 0.01)\n",
    "    fit_fn = np.poly1d(fit)\n",
    "    future_fit = np.polyval(fit_fn, future)\n",
    "    ax.plot(future, future_fit, color='Red', lw=3)\n",
    "    ax.set_title(title, fontsize = 25)\n",
    "\n",
    "    sns.despine()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rpy2\n",
    "\n",
    "%load_ext rpy2.ipython\n",
    "# Set up interface with R\n",
    "# Make it easy to set and find values in a multi-index DF\n",
    "idx = pd.IndexSlice\n",
    "# Set up interface with R\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import warnings\n",
    "from rpy2.rinterface import RRuntimeWarning\n",
    "warnings.filterwarnings(\"ignore\", category=RRuntimeWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "library(lme4)\n",
    "#library(car)\n",
    "library(optimx)\n",
    "#library(ggplot2)\n",
    "library(MASS)\n",
    "#library(broom)\n",
    "library(dplyr)\n",
    "library(reshape2)\n",
    "library(arm)\n",
    "library(multcomp)\n",
    "library(pbkrtest)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<script>\n",
    "  $(document).ready(function(){\n",
    "    $('div.prompt').hide();\n",
    "    $('div.back-to-top').hide();\n",
    "    $('nav#menubar').hide();\n",
    "    $('.breadcrumb').hide();\n",
    "    $('.hidden-print').hide();\n",
    "  });\n",
    "</script>\n",
    "\n",
    "<footer id=\"attribution\" style=\"float:right; color:#999; background:#fff;\">\n",
    "Created with Jupyter, delivered by Fastly, rendered by Rackspace.\n",
    "</footer>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
